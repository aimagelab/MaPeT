batch_size: 512
validation_batch_size: 512
num_classes: 1000
opt: adamw
momentum: 0.9
weight_decay: 0.05
sched: cosine
lr: 5e-3
warmup_lr: 1e-6
min_lr: 1e-6
warmup_epochs: 20
train_interpolation: bicubic
epochs: 200
smoothing: 0.1
aa: rand-m9-mstd0.5
reprob: 0.25
mixup: 0.8
cutmix: 1.0
drop_path: 0.1
amp: true
mean: [ 0.485, 0.456, 0.406 ]
std: [ 0.229, 0.224, 0.225 ]
layer_decay: 0.65
layer_scale_init_value: 0.1